{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. 프로젝트 : This is your playground! Leaderboard를 정복해 주세요!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ***캐글 리더보드의 Private score 기준 110000 이하의 점수***\n",
    " \n",
    " - 목표 : 어떤 조건을 가진 집의 가격이 높고 낮은지를 예측하는 모델을 만드는 것을 목표\n",
    " - 평가방식 : RMSE\n",
    " - train.csv - 예측 모델을 만들기 위해 사용하는 학습 데이터입니다. 집의 정보와 예측할 변수인 가격(Price) 변수를 가지고 있습니다.\n",
    " - test.csv - 학습셋으로 만든 모델을 가지고 예측할 가격(Price) 변수를 제외한 집의 정보가 담긴 테스트 데이터 입니다.\n",
    " - sample_submission.csv - 제출시 사용할 수 있는 예시 submission.csv 파일입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 라이브러리 import 하기\n",
    "\n",
    "import xgboost\n",
    "import lightgbm\n",
    "import missingno\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape = (15035, 21), test_data shape = (6468, 20)\n"
     ]
    }
   ],
   "source": [
    "# Dataset read & 크기 살펴보기\n",
    "# -> test 데이터는 Price 컬럼이 빠져있으므로 컬럼의 갯수가 적음\n",
    "\n",
    "train_data = pd.read_csv('./data/train.csv')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "\n",
    "print(f'train_data shape = {train_data.shape}, test_data shape = {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price            1.000000\n",
       "sqft_living      0.702899\n",
       "grade            0.667211\n",
       "sqft_above       0.608577\n",
       "sqft_living15    0.586419\n",
       "bathrooms        0.525479\n",
       "view             0.400806\n",
       "bedrooms         0.323672\n",
       "sqft_basement    0.322218\n",
       "lat              0.301604\n",
       "waterfront       0.265738\n",
       "floors           0.262588\n",
       "yr_renovated     0.140808\n",
       "sqft_lot         0.096793\n",
       "sqft_lot15       0.086384\n",
       "yr_built         0.047290\n",
       "condition        0.039740\n",
       "long             0.023547\n",
       "id               0.020899\n",
       "zipcode         -0.051498\n",
       "Name: price, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data.corr()['price'].sort_values(ascending=False)\n",
    "\n",
    "# # sqft_living , grade , sqft_above , sqft_living15 , bathrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 주요 컬럼 설명 \n",
    "\n",
    "ID : 집을 구분하는 번호\n",
    "\n",
    "date : 집을 구매한 날짜\n",
    "\n",
    "price : 타겟 변수인 집의 가격\n",
    "\n",
    "bedrooms : 침실의 수\n",
    "\n",
    "bathrooms : 침실당 화장실 개수\n",
    "\n",
    "sqft_living : 주거 공간의 평방 피트\n",
    "\n",
    "sqft_lot : 부지의 평방 피트\n",
    "\n",
    "floors : 집의 층 수\n",
    "\n",
    "waterfront : 집의 전방에 강이 흐르는지 유무 (a.k.a. 리버뷰)\n",
    "\n",
    "view : 집이 얼마나 좋아 보이는지의 정도\n",
    "\n",
    "condition : 집의 전반적인 상태\n",
    "\n",
    "grade : King County grading 시스템 기준으로 매긴 집의 등급\n",
    "\n",
    "sqft_above : 지하실을 제외한 평방 피트\n",
    "\n",
    "sqft_basement : 지하실의 평방 피트\n",
    "\n",
    "yr_built : 집을 지은 년도\n",
    "\n",
    "yr_renovated : 집을 재건축한 년도\n",
    "\n",
    "zipcode : 우편번호\n",
    "\n",
    "lat : 위도\n",
    "\n",
    "long : 경도\n",
    "\n",
    "sqft_living15 : 2015년 기준 주거 공간의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)\n",
    "\n",
    "sqft_lot15 : 2015년 기준 부지의 평방 피트(집을 재건축했다면, 변화가 있을 수 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 데이터셋 분리하고 train_data 에서 price 컬럼 drop 하기\n",
    "\n",
    "y = train_data['price']\n",
    "train_data.drop(labels=['price'], axis=1, inplace = True)\n",
    "\n",
    "# train, test 분리를 위하여 train data 의 길이를 저장\n",
    "tr_len = len(train_data)\n",
    "\n",
    "# 행 방향으로 trin, test 데이터 붙이기\n",
    "data = pd.concat((train_data, test_data), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 데이터 타입과 null 값 확인하기\n",
    "display(data.info())\n",
    "\n",
    "# -> Null 값이없고, 컬럼이 숫자값으로 구성된것을 확인 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 훈련용 데이터셋 살펴보기\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ID 컬럼 drop , 열 방향으로 drop\n",
    "\n",
    "data.drop(labels=['id'], axis=1, inplace = True)\n",
    "\n",
    "# date 컬럼 전처리 년,월,일 만 남기도록\n",
    "\n",
    "data['date'] = data['date'].apply(lambda x : str(x[:6])).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 완료된 데이터 확인\n",
    "\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 혹시 모르니 다시한번 null 값이 있는지 확인\n",
    "\n",
    "display(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 각 변수들의 분포 확인\n",
    "\n",
    "fig, ax = plt.subplots(9, 2, figsize=(20, 45))\n",
    "count = 1\n",
    "columns = data.columns\n",
    "for row in range(9):\n",
    "    for col in range(2):\n",
    "        sns.kdeplot(data=data[columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(columns[count], fontsize=15)\n",
    "        count += 1\n",
    "        if count == 19 :\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# skew 되어있는 데이터들을 np.log1p()를 통해서 로그 변환을 실행\n",
    "\n",
    "skew_columns = ['bedrooms', 'sqft_living', 'sqft_lot', 'sqft_above', 'sqft_basement', 'sqft_lot15', 'sqft_living15']\n",
    "\n",
    "for c in skew_columns:\n",
    "    data[c] = np.log1p(data[c].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.log1p()를 적용한 이후 데이터의 분포 모습\n",
    "\n",
    "fig, ax = plt.subplots(3, 2, figsize=(10, 15))\n",
    "\n",
    "count = 0\n",
    "for row in range(3):\n",
    "    for col in range(2):\n",
    "        if count == 5:\n",
    "            break\n",
    "        sns.kdeplot(data[skew_columns[count]], ax=ax[row][col])\n",
    "        ax[row][col].set_title(skew_columns[count], fontsize=15)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 데이터의 분포 확인\n",
    "# y 값 역시 왼쪽으로 skew 된것을 볼 수 있다.\n",
    "\n",
    "sns.histplot(y, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log1p를 이용하여 값을 변환\n",
    "# !!!! 나중에 모델이 값을 예측한 후에 다시 expm1()을 통해 값을 돌려 주어여함 !!!!\n",
    "\n",
    "y = np.log1p(y)\n",
    "\n",
    "sns.histplot(y, kde=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아까 합쳐두었던 train, test 데이터를 분리하기\n",
    "\n",
    "train_data = data.iloc[:tr_len, :].to_numpy()\n",
    "test_data = data.iloc[tr_len:, :].to_numpy()\n",
    "\n",
    "\n",
    "print(f'train_data shape = {train_data.shape}, test_data shape = {test_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base 모델 선정하기, train, test 나누고, rmse 정의하기\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def rmse(y_test, y_pred):\n",
    "    return np.sqrt(mean_squared_error(np.expm1(y_test), np.expm1(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_state는 모델초기화나 데이터셋 구성에 사용되는 랜덤 시드값입니다.   \n",
    "random_state=9999\n",
    "\n",
    "gboost = GradientBoostingRegressor(random_state=random_state)\n",
    "xgboost = XGBRegressor(random_state=random_state)\n",
    "lightgbm = LGBMRegressor(random_state=random_state)\n",
    "rdforest = RandomForestRegressor(random_state=random_state)\n",
    "\n",
    "models = [gboost, xgboost, lightgbm, rdforest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(models, train, y):\n",
    "    df = {}\n",
    "    \n",
    "    for model in models:\n",
    "        model_name = model.__class__.__name__\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(train, y, random_state=random_state, test_size=0.2)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        df[model_name] = rmse(y_test, y_pred)\n",
    "        score_df = pd.DataFrame(df, index=['RMSE']).T.sort_values('RMSE', ascending=False)\n",
    "            \n",
    "    return score_df\n",
    "get_scores(models, train_data, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss 값이 가장 낮은 lightgbm 모델을 base모델로 선정하고 하이퍼 파라미터 튜닝해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- max_depth : 의사 결정 나무의 깊이, 정수 사용\n",
    "\n",
    "- learning_rate : 한 스텝에 이동하는 양을 결정하는 파라미터, 보통 0.0001~0.1 사이의 실수 사용\n",
    "\n",
    "- n_estimators : 사용하는 개별 모델의 개수, 보통 50~100 이상의 정수 사용\n",
    "\n",
    "- num_leaves : 하나의 LightGBM 트리가 가질 수 있는 최대 잎의 수\n",
    "\n",
    "- boosting_type : 부스팅 방식, gbdt, rf 등의 문자열 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파라미터 값 지정을 위해서 Grid Search CV를 import / 파라미터 설정하기\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100,150,200],\n",
    "    'max_depth': [10, 20, 30],\n",
    "    'num_leave': [1,2,3,4],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lgbm 모델 선언하고 학습함수 선언하기\n",
    "\n",
    "model = LGBMRegressor(random_state=random_state)\n",
    "\n",
    "def my_GridSearch(model, train, y, param_grid, verbose=2, n_jobs=5):\n",
    "    # GridSearchCV 모델로 초기화\n",
    "    grid_model = GridSearchCV(model, param_grid=param_grid, scoring='neg_mean_squared_error', \\\n",
    "                              cv=5, verbose=verbose, n_jobs=n_jobs)\n",
    "    \n",
    "    # 모델 fitting\n",
    "    grid_model.fit(train, y)\n",
    "\n",
    "    # 결과값 저장\n",
    "    params = grid_model.cv_results_['params']\n",
    "    score = grid_model.cv_results_['mean_test_score']\n",
    "    \n",
    "    # 데이터 프레임 생성\n",
    "    results = pd.DataFrame(params)\n",
    "    results['score'] = score\n",
    "    \n",
    "    # RMSLE 값 계산 후 정렬\n",
    "    results['RMSLE'] = np.sqrt(-1 * results['score'])\n",
    "    results = results.sort_values('RMSLE')\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_test = my_GridSearch(model, train_data, y, param_grid)\n",
    "\n",
    "print(param_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_depth = 10 , n_estimators =  200, num_leave = 2 일때 RMSLE 값이 제일 낮다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에서 얻은 결과를 기반으로 하이퍼 파라미터 값 설정\n",
    "# test_data 가 있기때문에 train_test_split()는 진행하지 않음\n",
    "\n",
    "model = LGBMRegressor(max_depth=10, n_estimators=200,num_leave=1, random_state=random_state)\n",
    "\n",
    "model.fit(train_data, y)\n",
    "prediction = model.predict(test_data)\n",
    "\n",
    "# log1p()를 적용했기 때문에 empm1()으로 값을 다시 되돌려야한다.\n",
    "prediction = np.expm1(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submission 파일 읽어오기\n",
    "submission = pd.read_csv('./data/sample_submission.csv')\n",
    "\n",
    "# 모델이 예측한 결과값을 price 컬럼에 추가하기\n",
    "submission['price'] = prediction\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용 파일 csv 파일로 저장하기\n",
    "\n",
    "submission.to_csv('./data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
